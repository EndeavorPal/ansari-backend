{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "#PATH = '...' # Add the path to the current director. \n",
    "#sys.path.append(PATH)\n",
    "from agents.ansari import Ansari\n",
    "import random\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Environment, FileSystemLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenv = Environment(loader=FileSystemLoader('templates'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_temp = tenv.get_template('ask_question.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('batik-v1.csv')\n",
    "cache  = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question): \n",
    "    print(f'Answering question: {question[\"question\"]}')\n",
    "    options = [o.strip() for o in question['options'].split(',')]\n",
    "    prompt = q_temp.render(question=question['question'], options = options)\n",
    "    if prompt in cache.keys(): \n",
    "        print(f'Found {question[\"question\"]} in cache')\n",
    "        return cache[prompt]\n",
    "    ansari = Ansari()\n",
    "    result = ''.join(filter(lambda x: x is not None, ansari.process_input(prompt)))\n",
    "    print(f'Answer: {result}')\n",
    "    cache[prompt] = result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cache.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['json_prediction'] = df.apply(answer_question, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['json_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prediction(row):\n",
    "    raw = row['json_prediction']\n",
    "    raw = raw.replace('```','')\n",
    "    raw = raw.replace('json','')\n",
    "    raw = '{' + raw.split('{')[1]\n",
    "    raw = raw.split('}')[0] + '}'\n",
    "    raw = raw.strip()\n",
    "    print('raw is', raw)\n",
    "    raw_dict = json.loads(raw)\n",
    "    return str(raw_dict['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct(row):\n",
    "    clean_prediction = row['predicted'].strip().lower()\n",
    "    clean_correct = row['correct'].replace('Ayah','').strip().lower()\n",
    "    return clean_correct == clean_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted'] = df.apply(extract_prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correct_prediction'] = df.apply(is_correct, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correct_prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['correct_prediction'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "def answer_question_gpt4(question): \n",
    "    print(f'Answering question: {question[\"question\"]}')\n",
    "    options = [o.strip() for o in question['options'].split(',')]\n",
    "    prompt = q_temp.render(question=question['question'], options = options)\n",
    "    response = litellm.completion(\n",
    "        model = 'gpt-4-1106-preview',\n",
    "        messages = [ {\n",
    "                        'role': 'system', \n",
    "                        'content': 'You are a helpful assistant.'\n",
    "                    },\n",
    "                     {'role' : 'user', \n",
    "                      'content' : prompt \n",
    "                      } ],\n",
    "        timeout = 30.0,\n",
    "        temperature = 0.0,  \n",
    "        metadata = {'generation-name': 'ansari'},  \n",
    "        #response_format= { \"type\" : \"json_object\" }, \n",
    "        num_retries = 5                  \n",
    "    )\n",
    "    result = response.choices[0].message\n",
    "    print(f'Answer: {result}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gpt4_prediction'] = df.apply(answer_question_gpt4, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prediction_gpt4(row):\n",
    "    raw = row['gpt4_prediction'].content\n",
    "    raw = raw.replace('```','')\n",
    "    raw = raw.replace('json','')\n",
    "    raw = '{' + raw.split('{')[1]\n",
    "    raw = raw.split('}')[0] + '}'\n",
    "    raw = raw.strip()\n",
    "    print('raw is', raw)\n",
    "    raw_dict = json.loads(raw)\n",
    "    return str(raw_dict['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_gpt4'] = df.apply(extract_prediction_gpt4, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct_gpt4(row):\n",
    "    clean_prediction = row['predicted_gpt4'].strip().lower()\n",
    "    clean_correct = row['correct'].replace('Ayah','').strip().lower()\n",
    "    return clean_correct == clean_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gpt4_correct_prediction'] = df.apply(is_correct_gpt4, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gpt4_correct_prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['correct_prediction'] != df['gpt4_correct_prediction']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
